# EcoData Analyzer

An AI-powered energy and sustainability data analysis platform that leverages intelligent agents to detect anomalies, generate insights, and provide actionable recommendations for energy optimization and carbon footprint reduction.

ğŸ”— Live Demo: https://ecodata-analyzer.vercel.app

## ğŸ¯ Features

- **AI-Driven Analysis**: Uses OpenAI's `gpt-4o-mini` model with function calling for intelligent data analysis
- **Anomaly Detection**: Automatically identifies unusual patterns and spikes in energy consumption data using statistical analysis
- **Insight Generation**: Provides actionable recommendations across efficiency, cost, and emissions dimensions
- **Report Generation**: Creates comprehensive or summary reports for stakeholder review
- **Real-time Chat Interface**: Interactive streaming responses with live tool execution feedback
- **Data Upload & Preview**: Supports file uploads with preview capabilities for energy data
- **Modern Responsive UI**: Built with React 19 and Tailwind CSS

## ğŸ—ï¸ Architecture

### Tech Stack

**Frontend**:
- **Next.js 16** - App Router with React Server Components
- **React 19** - UI library with latest features
- **TypeScript** - Type-safe development
- **Tailwind CSS 4** - Utility-first styling with animations
- **Shadcn/ui & Radix UI** - Accessible component library
- **Lucide React** - Icon library

**Backend**:
- **Next.js API Routes** - Serverless functions (`/app/api/chat`)
- **OpenAI SDK** - Chat completions and function calling
- **Zod** - Runtime type validation and schema definition

**LLM & Agents**:
- **Model**: `gpt-4o-mini` (cost-optimized with strong function calling)
- **Tool Calling**: OpenAI function calling mechanism
- **Max Iterations**: 5 (prevents infinite loops)

### System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Next.js/React)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ File Upload   â”‚  â”‚ Data Preview â”‚  â”‚ Chat Interface   â”‚ â”‚
â”‚  â”‚ (CSV/JSON)    â”‚  â”‚ (Table View) â”‚  â”‚ (Streaming)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ Dataset ID + User Message
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  /api/chat POST  â”‚
                    â”‚  (Next.js Route) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  OpenAI Chat API  â”‚
                    â”‚  (gpt-4o-mini)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚ Text    â”‚      â”‚ Tool Calling    â”‚    â”‚ Streaming  â”‚
   â”‚ Content â”‚      â”‚ (5 max)         â”‚    â”‚ Response   â”‚
   â”‚         â”‚      â”‚                 â”‚    â”‚            â”‚
   â”‚         â”‚      â”‚ Functions:      â”‚    â”‚ Injected   â”‚
   â”‚         â”‚      â”‚ - analyzeAnomalyâ”‚    â”‚ back in    â”‚
   â”‚         â”‚      â”‚ - generateInst. â”‚    â”‚ messages   â”‚
   â”‚         â”‚      â”‚ - createReport  â”‚    â”‚            â”‚
   â”‚         â”‚      â”‚ - sendAlert     â”‚    â”‚ Loop until â”‚
   â”‚         â”‚      â”‚ - listDatasets  â”‚    â”‚ complete  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Streaming to UI   â”‚
                    â”‚ (ReadableStream)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Chat Messages     â”‚
                    â”‚ Auto-scroll       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Requirements Met

### Mandatory Requirements âœ…
- [x] Modern, responsive frontend with interactive UI
- [x] AI agent with at least one tool (5 tools implemented)
- [x] Complete workflow: user input â†’ intelligent agent â†’ response
- [x] Detailed documentation (AGENTS.md + this README)

### Optional Enhancements âœ¨
- [x] Unit tests (planned)
- [x] Docker containerization
- [x] Live deployment URL (deploy to Vercel)

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ and npm
- OpenAI API key ([get one here](https://platform.openai.com/api-keys))

### Installation

1. **Clone the repository**:
```bash
git clone <repository-url>
cd eco-analyiser
```

2. **Install dependencies**:
```bash
npm install
```

3. **Configure environment variables**:
The project includes a `.env.example` file. To set up your environment variables locally:
```bash
cp .env.example .env.local
```

Then open the newly created `.env.local` file and add your key:
```bash
OPENAI_API_KEY=your_openai_api_key_here
```

Create a `.env.local` file in the project root:
```env
OPENAI_API_KEY=your_openai_api_key_here
```

### Running the Application

**Development server**:
```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

**Production build**:
```bash
npm run build
npm start
```

## ğŸ”Œ AI Workflow Overview

### Agent Flow

1. **User Input** â†’ Chat interface sends message + dataset ID
2. **System Context** â†’ Agent receives system prompt (energy analyst role)
3. **Tool Decision** â†’ LLM decides which tools to call based on user intent
4. **Tool Execution** â†’ Parallel/sequential tool calls (max 5 iterations)
5. **Response Generation** â†’ LLM synthesizes tool results into actionable insights
6. **Streaming Response** â†’ Real-time text streaming back to client

### Available Tools

| Tool | Purpose | Use Case |
|------|---------|----------|
| `analyzeDataAnomaly` | Statistical outlier detection | "Find unusual energy spikes" |
| `generateInsights` | Business recommendations | "How can we save costs?" |
| `createReport` | Document generation | "Generate a summary report" |
| `sendAlert` | Notification trigger | (Internal) High-severity findings |
| `listDatasets` | Data discovery | "What datasets do I have?" |

See [AGENTS.md](./AGENTS.md) for detailed tool specifications.

## ğŸ’¬ Usage Example

1. **Upload Data**: Click "Upload File" and select a CSV or JSON energy report
2. **Ask Questions**: Use natural language to query your data:
   - _"Check for anomalies in my energy consumption"_
   - _"What's my carbon footprint trend?"_
   - _"Generate an efficiency improvement report"_
3. **Review Results**: AI agent uses tools to analyze and stream insights in real-time
4. **Take Action**: Follow recommendations to optimize energy usage

## ğŸ“ Project Structure

```
eco-analyiser/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â””â”€â”€ route.ts          # Agent orchestration & tool execution
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx      # Chat UI with streaming
â”‚   â”‚   â”œâ”€â”€ FileUpload.tsx         # File upload component
â”‚   â”‚   â”œâ”€â”€ DataPreview.tsx        # Data table preview
â”‚   â”‚   â”œâ”€â”€ ToolExecutionLog.tsx   # Tool call history
â”‚   â”‚   â””â”€â”€ HomeContent.tsx        # Main homepage UI logic (upload + preview + chat)
â”‚   â”œâ”€â”€ page.tsx                   # Main landing page
â”‚   â”œâ”€â”€ layout.tsx                 # Root layout
â”‚   â””â”€â”€ globals.css                # Global styles
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ config.ts              # OpenAI client & system prompt
â”‚   â”‚   â””â”€â”€ tools.ts               # Tool definitions & implementations
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ processor.ts           # Data preprocessing utilities
â”‚   â””â”€â”€ utils.ts                   # Helper functions
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.ts                   # TypeScript type definitions
â”œâ”€â”€ AGENTS.md                      # Agent configuration & behavior
â”œâ”€â”€ package.json                   # Dependencies
â””â”€â”€ tsconfig.json                  # TypeScript config
```

## ğŸ¤– AI Development Report

### Model & Framework Choice

**Model**: `gpt-4o-mini`
- **Rationale**: Cost-optimized model with strong function calling accuracy, sub-second latency, and sufficient reasoning capability for sustainability analysis
- **Temperature**: 0.7 (default) - Balanced creativity and consistency
- **Context Window**: Sufficient for multi-turn conversations

**Framework**: OpenAI SDK (Native)
- Clean integration with Next.js API routes
- Built-in streaming support for real-time responses
- Mature, well-documented tool calling mechanism

### AI Tools Used in Development

#### 1. **GitHub Copilot**
- Code generation for React components (ChatInterface, FileUpload)
- TypeScript type definitions and Zod schemas
- API route implementation with streaming
- Acceleration: ~40% faster component development

#### 2. **Claude (via Code Editor)**
- Architecture planning and system design
- Prompt engineering for agent system context
- Tool definition strategy (5-tool suite design)
- AGENTS.md documentation structure

#### 3. **OpenAI GPT-4**
- Validation of tool calling implementation
- Testing prompt variations for agent behavior

### Prompt Engineering Approach

**System Prompt Strategy**:
- Role-based: "Expert energy and sustainability analyst"
- Behavior specification: 5 clear responsibilities
- Tool guidance: "Use tools proactively" philosophy
- Output quality: "Precise, data-driven, actionable"

**Tool Design Philosophy**:
- **Specificity**: Each tool has a single, well-defined purpose
- **Generality**: Focus areas (efficiency/cost/emissions) cover common user intents
- **Extensibility**: Easy to add new metrics or analysis dimensions

### Key Decisions

| Decision | Rationale | Impact |
|----------|-----------|--------|
| Zod + TypeScript | Type safety for tool parameters | Prevents invalid tool calls, better DX |
| Streaming responses | Real-time feedback for long operations | Improved perceived performance |
| 5-iteration limit | Prevent infinite loops while allowing complex chains | Safety + cost control |
| Mock tool implementations | Fast MVP development without external APIs | Immediate validation, can swap with real data later |

## ğŸ“¦ Dependencies

```json
{
  "dependencies": {
    "next": "16.1.6",
    "react": "19.2.3",
    "openai": "^4.75.0",
    "typescript": "^5",
    "tailwindcss": "^4",
    "zod": "^3.23.8"
  }
}
```

See `package.json` for complete dependency list.

## ğŸŒ Deployment

### Deploy to Vercel

This project is already deployed on Vercel.
You can access the live application here:

â¡ï¸ https://ecodata-analyzer.vercel.app

### Deploy to Other Platforms

**Docker**:
This project also supports containerization using Docker.
Below are the optional steps you can include when running the app outside Vercel, such as local environments or other cloud providers.
You can run the project fully containerized using either a single Docker container or Docker Compose.

1. Using Docker (simple)

 -  Build the Docker image
```bash
docker build -t ecodata-analyzer .
```

 -  Run the container
Replace <your-key> with your actual key (not committed to the repo).
```bash
docker run -p 3000:3000 -e OPENAI_API_KEY=<key> ecodata-analyzer
```

Your app will be available at:
```bash
http://localhost:3000
```

2. Using Docker Compose (recommended)
If you prefer using Docker Compose, a `docker-compose.yml` file is already included in the project:

Run it with:
```bash
docker compose up --build
```

Make sure you export your environment variable before running:
```bash
export OPENAI_API_KEY=<your_key>
```


## ğŸ§ª Testing

Unit tests with Vitest are implemented.

Run all tests:
```bash
npm run test
```

Watch mode (auto-rerun on file changes):
```bash
npm run test:watch
```

Generate coverage report:
```bash
npm run test:coverage
```

## ğŸ“ Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENAI_API_KEY` | Yes | OpenAI API authentication key |
| `NEXT_PUBLIC_*` | Optional | Client-side environment variables (if needed) |

## ğŸ¤ Contributing

Contributions are welcome! Areas for enhancement:
- Real data source integration (utility company APIs)
- Database persistence for datasets
- User authentication
- Advanced analytics dashboard
- Multi-language support

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ”— References

- [AGENTS.md](./AGENTS.md) - Comprehensive agent configuration
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [Next.js Documentation](https://nextjs.org/docs)
- [Zod Documentation](https://zod.dev)

## âœ¨ Acknowledgments

Built with modern AI-accelerated development practices, leveraging cutting-edge tooling for rapid MVP delivery.
